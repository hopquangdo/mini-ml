{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-13T07:09:39.386193Z",
     "start_time": "2025-07-13T07:09:38.193654Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from models.linear_model import LogisticRegression as MyLogisticRegression\n",
    "from models.neighbors import KNeighborsClassifier as MyKNeighborsClassifier\n",
    "from models.svm import SVC as MySVC\n",
    "from models.tree import DecisionTreeClassifier as MyDecisionTreeClassifier\n",
    "from models.multiclass import OneVsRestClassifier"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T07:09:39.642143Z",
     "start_time": "2025-07-13T07:09:39.597430Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df = pd.read_csv(\"./dataset/housing_train.csv\")\n",
    "test_df = pd.read_csv(\"./dataset/housing_test.csv\")"
   ],
   "id": "23e304cef31f17c5",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T07:09:39.665370Z",
     "start_time": "2025-07-13T07:09:39.659470Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train = train_df.drop(columns=[\"LivingLevel\"])\n",
    "y_train = train_df[\"LivingLevel\"]\n",
    "X_test = test_df.drop(columns=[\"LivingLevel\"])\n",
    "y_test = test_df[\"LivingLevel\"]"
   ],
   "id": "fce9ad18b9b064fd",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T02:18:38.414105Z",
     "start_time": "2025-07-13T02:18:36.240103Z"
    }
   },
   "cell_type": "code",
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"SVM\": SVC()\n",
    "}\n",
    "target_names = [\"Low\", \"Medium\", \"High\"]\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"=== {name} ===\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "    print(\"-\" * 40)"
   ],
   "id": "a5846d2149128d6e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Logistic Regression ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Low       0.99      0.96      0.97      1063\n",
      "      Medium       0.96      0.98      0.97      1983\n",
      "        High       0.97      0.96      0.97      1082\n",
      "\n",
      "    accuracy                           0.97      4128\n",
      "   macro avg       0.97      0.97      0.97      4128\n",
      "weighted avg       0.97      0.97      0.97      4128\n",
      "\n",
      "----------------------------------------\n",
      "=== KNN ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Low       0.97      0.96      0.96      1063\n",
      "      Medium       0.95      0.96      0.95      1983\n",
      "        High       0.95      0.95      0.95      1082\n",
      "\n",
      "    accuracy                           0.95      4128\n",
      "   macro avg       0.96      0.95      0.96      4128\n",
      "weighted avg       0.95      0.95      0.95      4128\n",
      "\n",
      "----------------------------------------\n",
      "=== SVM ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Low       0.99      0.98      0.99      1063\n",
      "      Medium       0.98      0.99      0.99      1983\n",
      "        High       0.99      0.99      0.99      1082\n",
      "\n",
      "    accuracy                           0.99      4128\n",
      "   macro avg       0.99      0.99      0.99      4128\n",
      "weighted avg       0.99      0.99      0.99      4128\n",
      "\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T07:09:41.580977Z",
     "start_time": "2025-07-13T07:09:40.136244Z"
    }
   },
   "cell_type": "code",
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": OneVsRestClassifier(base_model_class=MyLogisticRegression, max_iter=1000)\n",
    "}\n",
    "target_names = [\"Low\", \"Medium\", \"High\"]\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"=== {name} ===\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "    print(\"-\" * 40)"
   ],
   "id": "793781ed6ea6e3d6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Logistic Regression ===\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [4128, 8256]",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 10\u001B[39m\n\u001B[32m      8\u001B[39m model.fit(X_train, y_train)\n\u001B[32m      9\u001B[39m y_pred = model.predict(X_test)\n\u001B[32m---> \u001B[39m\u001B[32m10\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[43mclassification_report\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget_names\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtarget_names\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[32m     11\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33m-\u001B[39m\u001B[33m\"\u001B[39m * \u001B[32m40\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mF:\\app\\python\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001B[39m, in \u001B[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    212\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    213\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[32m    214\u001B[39m         skip_parameter_validation=(\n\u001B[32m    215\u001B[39m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[32m    216\u001B[39m         )\n\u001B[32m    217\u001B[39m     ):\n\u001B[32m--> \u001B[39m\u001B[32m218\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    219\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    220\u001B[39m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[32m    221\u001B[39m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[32m    222\u001B[39m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[32m    223\u001B[39m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[32m    224\u001B[39m     msg = re.sub(\n\u001B[32m    225\u001B[39m         \u001B[33mr\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mparameter of \u001B[39m\u001B[33m\\\u001B[39m\u001B[33mw+ must be\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    226\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc.\u001B[34m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m must be\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    227\u001B[39m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[32m    228\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32mF:\\app\\python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2923\u001B[39m, in \u001B[36mclassification_report\u001B[39m\u001B[34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001B[39m\n\u001B[32m   2815\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Build a text report showing the main classification metrics.\u001B[39;00m\n\u001B[32m   2816\u001B[39m \n\u001B[32m   2817\u001B[39m \u001B[33;03mRead more in the :ref:`User Guide <classification_report>`.\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m   2919\u001B[39m \u001B[33;03m<BLANKLINE>\u001B[39;00m\n\u001B[32m   2920\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m   2922\u001B[39m y_true, y_pred = attach_unique(y_true, y_pred)\n\u001B[32m-> \u001B[39m\u001B[32m2923\u001B[39m y_type, y_true, y_pred = \u001B[43m_check_targets\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2925\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m labels \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m   2926\u001B[39m     labels = unique_labels(y_true, y_pred)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mF:\\app\\python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:97\u001B[39m, in \u001B[36m_check_targets\u001B[39m\u001B[34m(y_true, y_pred)\u001B[39m\n\u001B[32m     70\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001B[39;00m\n\u001B[32m     71\u001B[39m \n\u001B[32m     72\u001B[39m \u001B[33;03mThis converts multiclass or binary types to a common shape, and raises a\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m     94\u001B[39m \u001B[33;03my_pred : array or indicator matrix\u001B[39;00m\n\u001B[32m     95\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m     96\u001B[39m xp, _ = get_namespace(y_true, y_pred)\n\u001B[32m---> \u001B[39m\u001B[32m97\u001B[39m \u001B[43mcheck_consistent_length\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     98\u001B[39m type_true = type_of_target(y_true, input_name=\u001B[33m\"\u001B[39m\u001B[33my_true\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     99\u001B[39m type_pred = type_of_target(y_pred, input_name=\u001B[33m\"\u001B[39m\u001B[33my_pred\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mF:\\app\\python\\Lib\\site-packages\\sklearn\\utils\\validation.py:473\u001B[39m, in \u001B[36mcheck_consistent_length\u001B[39m\u001B[34m(*arrays)\u001B[39m\n\u001B[32m    471\u001B[39m lengths = [_num_samples(X) \u001B[38;5;28;01mfor\u001B[39;00m X \u001B[38;5;129;01min\u001B[39;00m arrays \u001B[38;5;28;01mif\u001B[39;00m X \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m]\n\u001B[32m    472\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mset\u001B[39m(lengths)) > \u001B[32m1\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m473\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    474\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mFound input variables with inconsistent numbers of samples: \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m    475\u001B[39m         % [\u001B[38;5;28mint\u001B[39m(l) \u001B[38;5;28;01mfor\u001B[39;00m l \u001B[38;5;129;01min\u001B[39;00m lengths]\n\u001B[32m    476\u001B[39m     )\n",
      "\u001B[31mValueError\u001B[39m: Found input variables with inconsistent numbers of samples: [4128, 8256]"
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
